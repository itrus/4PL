---
title: "4PL curve fitting"
output:
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: tango
date: "2022-12-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = TRUE,
	warning = TRUE
)
```

# Initialization

```{r loading packages}
library(magrittr)
library(reshape)
library(plyr)
library(ggplot2)
library(investr)
library(minpack.lm)
library(plotrix)
library(nlstools)
```

# Data loading and processing

```{r loading data}
cat("Loading dataset...")
DF <- read.csv2("input_data.csv", header = T, dec = ".")
DF <- DF[order(DF$conc), ]
print(DF)
DF <- DF %>% melt(id = c("conc")) %>% na.omit()
colnames(DF)[3] <- "od"
DF$conc <- 10^DF$conc
DF <- DF[order(DF$conc), ]
rownames(DF) <- NULL
str(DF)
cat("Descriptive statistics.")
DF.sum <- ddply(DF, .(conc), summarise, n = length(na.omit(od)),
                mean.od = mean(od, na.rm = TRUE),
                var.od = var(od, na.rm = TRUE))
DF.sum
cat("Min and max values.")
DFMinMax <- ddply(DF, .(conc), summarise, n = length(na.omit(od)), 
              Min = min(od, na.rm = TRUE), Max = max(od, na.rm = TRUE))
DFMinMax
par(mfrow = c(1, 2), cex.main = 1, mar = c(4, 4, 1, 2), oma = c(0.5, 0.5, 2.5, 0))
plot(DF$conc, DF$od, pch = 21, bg = "grey", ylab = "Response [%]", 
     xlab = "Concentration [abs]")
plot(log(DF$conc), DF$od, pch = 21, bg = "grey", ylab = "Response [%]", 
     xlab = "Concentration [log]")
grid()
title("Data: concentration on absolute (left) and log (right) scales", outer = T)
par(mfrow = c(1, 1))
```

# Modeling the variability with variance regression

Checking mean response and variance of the response with power function (Dunn and Wild 2013): `Var(y)=intercept∗Mean(y)^theta`

Linearised function: `log(Var(y))=log(intercept)+theta∗log(Mean(y))`

```{r variability}
DF.sum$log.mean.od <- log(DF.sum$mean.od)
DF.sum$log.var.od <- log(DF.sum$var.od)
var.reg <- lm(log.var.od ~ log.mean.od, data = DF.sum)
summary(var.reg)
theta <- coef(var.reg)[[2]]
ggplot(aes(y = log.var.od, x = log.mean.od), data = DF.sum) +
  geom_point(size = 4, shape = 21, fill = "grey") +
  stat_function(fun = function(x) coef(var.reg)[[1]] + coef(var.reg)[[2]] * x) +
  ggtitle("Variance regression shown on log scale")
ggplot(aes(y = var.od, x = mean.od), data = DF.sum) +
  geom_point(size = 4, shape = 21, fill = "grey") +
  stat_function(fun = function(x) exp(coef(var.reg)[[1]])*x^coef(var.reg)[[2]]) +
  ggtitle("Variance regression shown on abs scale")
confint(var.reg)
plotFit(var.reg, interval = "confidence", pch = 21, bg = "grey", shade = TRUE,
        main = "Variance regression with 95% confidence bands")
```

Theta estimation: for each 1 unit log(mean.response) increase, log(variance) increases `r theta` times.

# Curve fitting

## Unweighted nonlinear regression

```{r UW}
# ------------ Function: 4PL curve function ---------------------------------
M.4pl <- function(x, Top, Bottom, IC50, slope){
    f <- Top + ((Bottom - Top)/(1 + (x / IC50)^slope))
    return(f)
}
# ------------- end ---------------------------------------------------------

# a wrapper for fitted curve and residual plots
plotDiag.nls <- function(nlsLM.model, title.top){
    par(mfcol=c(1, 2), oma = c(0.5, 0.5, 2, 0))
    # adapted from Brandon Greenwell's investr functions
    data <- eval(nlsLM.model$data)
    x.names <- intersect(all.vars(formula(nlsLM.model)[[3]]), colnames(data))
    y.names <- all.vars(formula(nlsLM.model)[[2]])
    x <- data[, x.names]  # extract predictor columns
    x.nz.min <- min(x[x!=0])
    # Display purposes, we cheat a little to get the zero calibrators included on the
    # log(x) plot
    x.fix <- ifelse(x <= 0, x.nz.min/5, x)
    break.x <- x.nz.min/4
    y <- data[, y.names]  # extract response columns
    # Plot data and fitted curve
    plot(x.fix, y, log = "x", main = "data and fitted curve", pch = 20,
         ylab = "Response", xlab = "log(Concentration)", font.main = 3)
    grid()
    curve(M.4pl(x, coef(nlsLM.model)[[1]], coef(nlsLM.model)[[2]], 
                coef(nlsLM.model)[[3]], coef(nlsLM.model)[[4]]), add = T)
    # Technically, we should not include the zero-calibrators on a log plot, but it's nice
    # to have for visualizing the results. This line inserts a break in the x-axis as in
    # Dudley et al (1985)
    axis.break(1, break.x, brw = 0.05)
    # Plot standardised weighted residuals
    # [add ifelse condition for weighted and unweighted models (title)]
    std.w.resid <- summary(nlsLM.model)$resid/sd(summary(nlsLM.model)$resid)
    plot(predict(nlsLM.model), std.w.resid, ylab = "std residuals (in SDs)", 
         xlab = "fitted response values", pch = 20, 
         main = "standardized residuals", font.main = 3)
    # Horizontal lines at y=0 and +/- 2SD
    abline(h = 0, lty = 3, col = "red")
    abline(h = 2, lty = 3)
    abline(h = -2, lty = 3)
    title(main = title.top, outer = TRUE)
    par(mfcol=c(1, 1))
}

# Create a vector with the starting values
# (The order of the parameters is important. It determines the list index number in later functions.)
start.DF <- c(Top = 1, Bottom = 0.2, IC50 = 10, slope = -1)
uw.4pl <- nlsLM(od ~ M.4pl(conc, Top, Bottom, IC50, slope), 
                data = DF,
                start = start.DF,
                control = nls.lm.control(maxiter = 1000))
summary(uw.4pl)
plotDiag.nls(uw.4pl, "Unweighted 4PL calibration model")
```

## Weighted nonlinear regression

```{r W}
y.curve <- predict(uw.4pl)
w.4pl <- nlsLM(od ~ M.4pl(conc, Top, Bottom, IC50, slope), 
               data = DF,
               start = start.DF,
               weights = (1 / y.curve^theta),
               control = nls.lm.control(maxiter = 1000)
               )
summary(w.4pl)
plotDiag.nls(w.4pl, "Weighted 4PL calibration model")
cat("What are the parts of the model object and summary object")
cat("Weights")
weights(w.4pl)
cat("Weights mean")
mean(weights(w.4pl))
cat("Weights sum")
sum(weights(w.4pl))
cat("Unweighted residuals")
resid(w.4pl)
cat("Unweighted sum of squares - use to compare models")
sum(resid(w.4pl)^2)
cat("Unweighted MSE")
sum(resid(w.4pl)^2)/summary(w.4pl)$df[[2]]
cat("Unweighted RSE")
sqrt(sum(resid(w.4pl)^2)/summary(w.4pl)$df[[2]])
cat("Weighted residuals - use this for plotting")
summary(w.4pl)$resid
cat("Weighted sum of squares")
sum(summary(w.4pl)$resid^2)
cat("RSE (sigma) - weighted")
summary(w.4pl)$sigma
```

## Iteratively reweighted least squares algorithm

### Curve fitting

We need to estimate both the parameters of the 4PL function as well as the weight function. This can be done by iteratively applying the nlsLM function described above till the residual sum of squares does not reduce significantly. Below is a function that implements this iterative model fitting process. This is the same approach used in the GraphPad software program.

```{r IRLS}
#######################################################
#
# 4PL iteratively reweighted LS procedure:
#
#  1. args: df, y, x, theta, start values
#  2. unweighted model (nlsLM)
#  3. get important output (y.curve, wss) using summary3()
#  4. calculate weights (uses y.curve and theta)
#  5. weighted nlsLM
#  6. d.wss: calculate change in wss (wss1 - wss2) / wss1
#  7. if d.wss > 0.01 repeat from (3)
#
#########################################################

# Use dot '.' to specify class
IRLS.4pl <- function(df, y = "od", x = "conc", theta, 
                     start = c(Top = 1
                               , Bottom = 0
                               , IC50 = 10
                               , slope = -1)
)
{
    # Keep the original data set with the output object
    orig.data <- df
    # Function uses O'Connell's parameterization of theta
    theta2 <- theta/2
    # Insert variables into the 4pl formula 
    form.4pl <- paste(y, " ~ M.4pl(", x, ", Top, Bottom, IC50, slope)")
    # Unweighted model
    nls0 <- nlsLM(as.formula(form.4pl), data = df, start = start)
    # Get the predicted responses
    y.curve <- predict(nls0)
    # Weighted sum of squares
    wss0 <- sum(summary(nls0)$resid^2)
    # 1st iteration   
    nls1 <- nlsLM(as.formula(form.4pl), data = df, start = start, 
                  weights = (1 / (y.curve^2)^theta2))
    wss1 <- sum(summary(nls1)$resid^2)
    # Percent change in the weighted sum of squares to control iterations (count)
    d.wss <- abs(wss0 - wss1) / wss0
    count <- 1
    # Repeat fitting until WSS changes by less than 0.001%
    while (d.wss > (0.01*0.001)){
        count  <- count + 1
        y.curve <- predict(nls1)
        nls1 <- nlsLM(as.formula(form.4pl), data = df, start = start, 
                      weights = (1 / (y.curve^2)^theta2))
        d.wss <- abs(wss1 - sum(summary(nls1)$resid^2)) / wss1
        wss1 <- sum(summary(nls1)$resid^2)
    }
    return(list(orig.data = orig.data, start.model = nls0, cycles = count, end.model = nls1))
}
# An irls results wrapper
summaryIRLS <- function(irls.model){
    cat("\nThe unweighted model:\n")
    print(summary(irls.model$start.model))
    cat("---------------------------------------------------")
    cat("\nThe weighted sum of squares was stable after", 
        irls.model$cycles, "cycles\n\n")
    cat("---------------------------------------------------")
    cat("\nThe final model:\n")
    print(summary(irls.model$end.model))
    plot(log(unique(irls.model$orig.data$conc)), unique(predict(irls.model$start.model)), 
         type = 'b', col = "grey",
         ylab = "Fitted Response", xlab = "log(Concentration)", 
         main = "IRLS: unweighted and final weighted")
    points(log(unique(irls.model$orig.data$conc)), unique(predict(irls.model$end.model)), 
           type = 'b', 
           pch = 19, col = "red")
    legend(1, 0.9, legend = c("Unweighted", "Final weighted"), lty = 1, 
           col = c("grey", "red"))
    
}
# a wrapper for fitted curve and residual plots
plotDiag.irls <- function(irls.model, title.top){
    title.top <- "IRLS 4PL calibration model"
    par(mfcol=c(1, 2), oma = c(0.5, 0.5, 2, 0))
    # adapted from Brandon Greenwell's investr functions
    data <- irls.model$orig.data
    x.names <- intersect(all.vars(formula(irls.model$end.model)[[3]]), colnames(data))
    y.names <- all.vars(formula(irls.model$end.model)[[2]])
    x <- data[, x.names]  # extract predictor columns
    x.nz.min <- min(x[x!=0])
    # Display purposes, we cheat a little to get the zero calibrators included on the
    # log(x) plot
    x.fix <- ifelse(x <= 0, x.nz.min/5, x)
    break.x <- x.nz.min/4
    y <- data[, y.names]  # extract response columns
    # Plot data and fitted curve
    plot(x.fix, y, log = "x", main = "data and fitted curve", pch = 20,
         ylab = "Response", xlab = "log(Concentration)", font.main = 3)
    grid()
    curve(M.4pl(x, coef(irls.model$end.model)[[1]], coef(irls.model$end.model)[[2]], 
                coef(irls.model$end.model)[[3]], coef(irls.model$end.model)[[4]]), 
          add = T)
    axis.break(1, break.x, brw = 0.05)
    std.w.resid <- summary(irls.model$end.model)$resid/
        sd(summary(irls.model$end.model)$resid)
    plot(predict(irls.model$end.model), std.w.resid, ylab = "std residuals (in SDs)", 
         xlab = "fitted response values", pch = 20, 
         main = "standardized (weighted) residuals", font.main = 3)
    abline(h = 0, lty = 3, col = "red")
    abline(h = 2, lty = 3)
    abline(h = -2, lty = 3)
    title(main = title.top, outer = TRUE)
    par(mfcol=c(1, 1))
}
w2.4pl <- IRLS.4pl(df = DF, theta = theta, start = start.DF)
summaryIRLS(w2.4pl)
plotDiag.irls(w2.4pl, "IRLS 4PL calibration model")
# 95% confidence intervals for the parameters
cat("CI95%")
#print(confint(w2.4pl$end.model), digits = 4)
print(nlstools::confint2(w2.4pl$end.model), digits = 4)
cat("Weighted sum of squares")
print(sum(summary(w2.4pl$end.model)$resid^2), digits = 3)
cat("Sigma (RSE). Residual Standard Error (R'’'s sigma and GraphPad'’'s Sy.x) are virtually the same.")
print(summary(w2.4pl$end.model)$sigma, digits = 3)
```

### Error model

The following function returns a data frame of triplets: a range of response values (\`yp\`), corresponding predicted concentration (\`xp\`) and the standard deviation of the predicted concentration (\`sd.xp\`). Derive var(x) from calibration curve model. Adapted from S-PLUS code at <http://lib.stat.cmu.edu/S/calibration>. Values from vcov(model) = unscaled \* sigma\^2 but sumary(model)\$cov.unscaled is what we need. O'Connell p.103 (left column, about 1/2 page): "denotes the estimated covariance matrix for [beta-hat], unscaled by [sigma-hat]..." conf is confidence level for prediction interval

```{r error}
sdXhat.4pl <- function(irls.model 
                       # request theta from user since I do not know how to 
                       # get theta back out of object
                       , theta 
                       , m = 3  # check this
                       , vlen = 700){
    # model.sum is a irls.4pl() object (from above)
    model <- irls.model$end.model
    # theta <- theta.ocon.lit
    theta2 <- theta/2
    # Get some information from the original data    
    data <- irls.model$orig.data
    x.names <- intersect(all.vars(formula(model)[[3]]), colnames(data))
    y.names <- all.vars(formula(model)[[2]])
    x <- data[, x.names]  # extract predictor columns
    y <- data[, y.names]  # extract response columns    
    # Gather the bits and pieces
    # corresponding t value for requested confidence level 
    degree.freedom <- summary(model)$df[2]
    cov.un  <- summary(model)$cov.unscaled   # unscaled covariance matrix
    # O'Connell's parametrerisation for ascending curves is different
    # They keep beta positive and switch a and d
    b       <- coef(model)
    n       <- length(x)                        # sample size, n
    xpstart <- min(c(0.0005, min(x[x>0])))      # Setting the starting point for the grid
    # x values for grid
    xp      <- c(seq(xpstart, b[[3]], length = round(vlen / 2, 0)), 
                 seq(b[[3]], max(x), length = round(vlen / 2, 0)))
    # y values for grid
    yp      <- as.vector(M.4pl(xp, b[1], b[2], b[3], b[4]))
    # The derivatives
    dh.dy <- xp * (b[1]-b[2])/(b[4]*(yp - b[1]) * (b[2] - yp))
    dh.db1 <- xp/(b[4]*(yp - b[1]))
    dh.db2 <- xp/(b[4]*(b[2] - yp))
    dh.db3 <- xp/b[3]
    dh.db4 <- (-xp/(b[4]*b[4])) * log((b[2]-yp)/(yp-b[1]))
    # compute the estimated variance of the calibration estimate xp
    # sigma2 is the mean variance. In weighted models it is scaled by weights
    sigma2 <-  summary(model)$sigma^2  
    # The following corresponds to equation at bottom of p.111 of O'Connell (1993)
    # Note the Var(y) part:
    # Var(y) = sigma2 * (yp^theta) 
    # Our parameterization (from weights) uses y.curve^theta, not ^2*theta
    # If using an outside theta based on variance function as function of SD, not var, 
    # like in O'Connell, multiply by 2 first
    var.xnot.hat <- (dh.dy*dh.dy) * sigma2 * (yp^2)^theta2 / m +
        sigma2 * (dh.db1 * (  dh.db1 * cov.un[1,1]
                              + dh.db2 * cov.un[2,1]
                              + dh.db3 * cov.un[3,1]
                              + dh.db4 * cov.un[4,1])
                  + dh.db2 * (  dh.db1 * cov.un[1,2]
                                + dh.db2 * cov.un[2,2]
                                + dh.db3 * cov.un[3,2]
                                + dh.db4 * cov.un[4,2])
                  + dh.db3 * (  dh.db1 * cov.un[1,3]
                                + dh.db2 * cov.un[2,3]
                                + dh.db3 * cov.un[3,3]
                                + dh.db4 * cov.un[4,3])
                  + dh.db4 * (  dh.db1 * cov.un[1,4]
                                + dh.db2 * cov.un[2,4]
                                + dh.db3 * cov.un[3,4]
                                + dh.db4 * cov.un[4,4]))
    # Covert to standard deviation
    sd.xp <- sqrt(var.xnot.hat)
    # Gather yp and xp (grid) plus sd.xp into a data.frame
    inv.grid <- data.frame(yp, xp, sd.xp)
    # Drop any rowns containing NAs or infinite values
    inv.grid <- inv.grid[is.finite(inv.grid$sd.xp), ]
    # head(inv.grid, 10)
    return(list(inv.grid = inv.grid, model.degree.freedom = degree.freedom, 
                model.sigma2 = sigma2))
}
inv.theta <- sdXhat.4pl(w2.4pl, theta = theta)
head(inv.theta$inv.grid, 15) 
```
